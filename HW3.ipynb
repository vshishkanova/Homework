{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание №1\n",
    "\n",
    "Скачайте текст \"Литературных анекдотов\". Напишите функцию, которая будет читать файл, лемматизировать текст с помощью pymystem3 и записывать результат в новый файл. У функции должно бы два аргумента: путь к исходному файлу и путь к файлу с лемматизированным текстом. Вызов функции тоже должен быть прописан в решении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json\n",
    "from pymystem3 import Mystem\n",
    "from collections import Counter\n",
    "\n",
    "def lemm_in_file(filecom, fileout): #создаем функцию\n",
    "    \n",
    "    with open(filecom, 'r', encoding='utf-8') as f: #открываем и читаем файл\n",
    "        anecdotes = f.read()\n",
    "         \n",
    "    \n",
    "    m = Mystem() #лемматизируем\n",
    "    lemmas = m.lemmatize(anecdotes)\n",
    "    anecdotes_lemma = ''.join(lemmas) #совмещаем в строку через пробел\n",
    "     \n",
    "    with open(fileout, 'w', encoding='utf-8') as f: #пишем текст в новый файл\n",
    "        f.write(anecdotes_lemma)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите имя начального файла:\n",
      "literary_anecdotes.txt\n",
      "Введите имя нового файла:\n",
      "loltext.txt\n"
     ]
    }
   ],
   "source": [
    "lemm_in_file(input(\"Введите имя начального файла:\\n\"), input(\"Введите имя нового файла:\\n\")) #вызов функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание №2\n",
    "\n",
    "Очистите лемматизированный текст от стоп-слов и посчитайте ipm для оставшихся. Выведите 20 самых частотных по этому параметру слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('пушкин', 54), ('толстой', 33), ('гоголь', 31), ('однажды', 29), ('лев', 25), ('любить', 20), ('достоевский', 19), ('тургенев', 15), ('ребенок', 14), ('царствие', 13), ('окно', 12), ('тверской', 12), ('бульвар', 12), ('идти', 12), ('лермонтов', 12), ('приходить', 11), ('федор', 11), ('михайлович', 11), ('герцен', 10), ('небесный', 10)]\n"
     ]
    }
   ],
   "source": [
    "text_1= [w.strip(\"!\\\"#$%&'()*+,./:;<=>?@[\\]^_`{|}~„“«»†*—/\\-—\") for w in anecdotes_lemma.split()] #обрезаем пунктуацию\n",
    "text_2 = [w for w in text_1 if len(w) != 0] #убираем пустоты\n",
    "\n",
    "with open('rus_stopwords.txt', 'r', encoding='utf-8') as f: #чистим от стоп-слов.Открываем и читаем файл со стоп-словами\n",
    "    stopwords = f.read()\n",
    "\n",
    "stopwords = stopwords.split('\\n') #создаем список и разбиваем по переносу строки\n",
    "text_2 = [w for w in text_2 if w not in stopwords] #устанавливаем ограничение на все слова, за исключением стоп-слов\n",
    "\n",
    "calc = Counter(text_2) #считаем и выводим\n",
    "print(calc.most_common(20))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание №3\n",
    "\n",
    "Сделайте полный морфологический разбор исходного текста. Напишите регулярное выражение, которое будет извлекать из тега только часть речи. Пройдитесь циклом по списку с разборами, который выдал pymystem3, извлекая из каждого разбора форму слова и его часть речи и записывая их в новый словарь (форма -- ключ, часть речи -- значение). Посчитайте абсолютную частоту для всех частей речи, а затем относительнную частоту (абсолютная частота / длина текста в словах)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1355"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('literary_anecdotes.txt', 'r', encoding='utf-8') as f: #открываем и читаем текст исходного файла\n",
    "    morf = f.read()\n",
    "    \n",
    "morf_analyzed = m.analyze(morf)#анализируем\n",
    " \n",
    "vocab = {} #создаём грамматический словарь\n",
    "for word in morf_analyzed:\n",
    "    try:\n",
    "        form = word['text']\n",
    "        grammar = word['analysis'][0]['gr']\n",
    "        vocab[form] = grammar\n",
    "    except KeyError: #исключаем возможность ошибок\n",
    "        pass\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "pos = re.compile('[A-Z]+') #создаем регулярное выражение, извлекающее части речи\n",
    "\n",
    "newdict_pos = {} #создаем пустой словарь\n",
    "\n",
    "for k, v in vocab.items():#записываем в новый словарь ключ из начального словаря и значение\n",
    "    newdict_pos[k] = pos.match(v).group(0)\n",
    "    \n",
    "len(newdict_pos)#считаем длину текста в словах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
